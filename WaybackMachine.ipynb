{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wayback Machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES = [\"http://rss.cnn.com/rss/cnn_latest.rss\"]\n",
    "DOWNLOAD_ARCHIVES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wayback_versions(\n",
    "    url, from_timestamp=\"\", to_timestamp=\"\", max_versions=10, include_content=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch past versions of a URL from the Wayback Machine and optionally the content.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL to fetch past versions for.\n",
    "    - from_timestamp (str): Start timestamp in format YYYYmmddHHMMSS. Empty means no start limit.\n",
    "    - to_timestamp (str): End timestamp in format YYYYmmddHHMMSS. Empty means no end limit.\n",
    "    - max_versions (int): Maximum number of versions to fetch.\n",
    "    - include_content (bool): Whether to fetch the content of the archived URL.\n",
    "\n",
    "    Returns:\n",
    "    - list of dicts: Each dict contains 'timestamp', 'archive_url', and optionally 'archive_content'.\n",
    "    \"\"\"\n",
    "    base_url = \"http://web.archive.org/cdx/search/cdx\"\n",
    "    params = {\n",
    "        \"url\": url,\n",
    "        \"output\": \"json\",\n",
    "        \"from\": from_timestamp,\n",
    "        \"to\": to_timestamp,\n",
    "        \"limit\": max_versions,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if not data or len(data) < 2:\n",
    "            return []\n",
    "\n",
    "        versions = []\n",
    "        for item in data[1:]:\n",
    "            version_info = {\n",
    "                \"timestamp\": item[1],\n",
    "                \"url\": url,\n",
    "                \"archive_url\": f\"https://web.archive.org/web/{item[1]}/{url}\",\n",
    "            }\n",
    "            if include_content:\n",
    "                content_response = requests.get(version_info[\"archive_url\"])\n",
    "                content_response.raise_for_status()\n",
    "                version_info[\"archive_content\"] = content_response.text\n",
    "            versions.append(version_info)\n",
    "\n",
    "        return versions\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data from Wayback Machine: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_content(file_path, content):\n",
    "    \"\"\"\n",
    "    Saves content to a file, creating parent directories if they don't exist.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the file where content will be saved.\n",
    "    - content (str): The content to save to the file.\n",
    "    \"\"\"\n",
    "    # Convert the file_path string to a Path object\n",
    "    path = Path(file_path)\n",
    "\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with path.open(mode=\"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "\n",
    "def url_to_filepath(url, base_dir=\"web_content\", timestamp=None):\n",
    "    \"\"\"\n",
    "    Converts a URL to a file path, using a base directory, and optionally includes a timestamp\n",
    "    for versioning.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL to convert.\n",
    "    - base_dir (str): The base directory where the content will be stored.\n",
    "    - timestamp (str, optional): A timestamp string to include in the file path for versioning.\n",
    "\n",
    "    Returns:\n",
    "    - Path: A pathlib.Path object representing the file path.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    domain_name = parsed_url.netloc\n",
    "    path = parsed_url.path\n",
    "\n",
    "    clean_path = path.strip(\"/\")\n",
    "\n",
    "    path_parts = clean_path.split(\"/\") if clean_path else []\n",
    "\n",
    "    # Construct the file path from the base directory, domain name, and path parts\n",
    "    if path_parts:\n",
    "        # Extract the last part as the filename\n",
    "        filename = path_parts.pop()\n",
    "        # Identify the file extension\n",
    "        name, dot, extension = filename.partition(\".\")\n",
    "        # Insert the timestamp before the extension (if any)\n",
    "        if timestamp:\n",
    "            filename = (\n",
    "                f\"{name}{dot}{timestamp}{dot}{extension}\"\n",
    "                if dot\n",
    "                else f\"{name}{dot}{timestamp}\"\n",
    "            )\n",
    "        else:\n",
    "            filename = f\"{name}{dot}{extension}\"\n",
    "        path_parts.append(filename)\n",
    "\n",
    "    filepath = Path(base_dir, domain_name, *path_parts)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Archives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_ARCHIVES:\n",
    "    versions = []\n",
    "    for source in SOURCES:\n",
    "        source_versions = fetch_wayback_versions(\n",
    "            source, max_versions=5, include_content=True\n",
    "        )\n",
    "        versions.extend(source_versions)\n",
    "    for version in versions:\n",
    "        url = version[\"url\"]\n",
    "        timestamp = version[\"timestamp\"]\n",
    "        content = version[\"archive_content\"]\n",
    "        filepath = url_to_filepath(url, base_dir=\"data\", timestamp=timestamp)\n",
    "        save_content(filepath, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WaybackMachine-BiQ6x-X5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
